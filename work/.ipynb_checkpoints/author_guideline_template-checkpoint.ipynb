{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "citation-manager": {
     "citations": {
      "": []
     }
    },
    "tags": [
     "title"
    ]
   },
   "source": [
    "# Designing Our Digital Past\n",
    "## Anchoring Digital-History Tool Development in the Historical Method Through Design-Based History Research"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "contributor"
    ]
   },
   "source": [
    " ### Kalani Craig [![orcid](https://orcid.org/sites/default/files/images/orcid_16x16.png)](https://orcid.org/0000-0002-8909-0369) \n",
    "Department of History, College of Arts + Sciences Indiana University-Bloomington "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "contributor"
    ]
   },
   "source": [
    " ### Joshua Danish [![orcid](https://orcid.org/sites/default/files/images/orcid_16x16.png)](https://orcid.org/0000-0002-8909-0369) \n",
    "Learning Sciences, School of Education, Indiana University-Bloomington "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "copyright"
    ]
   },
   "source": [
    "[![cc-by-nc-nd](https://licensebuttons.net/l/by-nc-nd/4.0/88x31.png)](https://creativecommons.org/licenses/by-nc-nd/4.0/) \n",
    "© Kalani Craig and Joshua Danish. [Net.Create](https://www.netcreate.org) is funded through the [EAGER program](https://www.nsf.gov/pubs/policydocs/pappguide/nsf09_1/gpg_2.jsp#IID2) at the [National Science Foundation](https://www.nsf.gov/) under award #[1848655](https://www.nsf.gov/awardsearch/showAward?AWD_ID=1848655). Published by De Gruyter in cooperation with the University of Luxembourg Centre for Contemporary and Digital History. This is an Open Access article distributed under the terms of the [Creative Commons Attribution License CC-BY-NC-ND](https://creativecommons.org/licenses/by-nc-nd/4.0/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "cover"
    ]
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV4AAACWBAMAAABkyf1EAAAAG1BMVEXMzMyWlpacnJyqqqrFxcWxsbGjo6O3t7e+vr6He3KoAAAACXBIWXMAAA7EAAAOxAGVKw4bAAAEcElEQVR4nO2aTW/bRhCGh18ij1zKknMkbbf2UXITIEeyMhIfRaF1exQLA/JRclslRykO+rs7s7s0VwytNmhJtsA8gHZEcox9PTs7uysQgGEYhmEYhmEYhmEYhmEYhmEYhmEYhmEYhmEYhmEYhmGYr2OWRK/ReIKI8Zt7Hb19wTcQ0uTkGh13bQupcw7gPOvdo12/5CzNtNR7xLUtNtT3CGBQ6g3InjY720pvofUec22LJPr8PhEp2OMPyI40PdwWUdronCu9yQpdPx53bQlfLKnfOVhlnDYRBXve4Ov+IZTeMgdedm0NR+xoXJeQvdJ3CvziykSukwil16W/Oe7aGjIjqc/9ib4jQlJy0uArtN4A0+cvXFvDkmUJ47sJ1Y1ATLDNVXZkNPIepQzxy1ki9fqiwbUj/I+64zxWNzyZnPuhvohJ9K70VvXBixpcu2SAHU+Xd9EKdEJDNpYP3AQr3bQSpPQ6Y6/4dl1z7ZDbArsszjA7L0g7ibB0CDcidUWVoErvIMKZh2Xs0LUzcLW6V5NfiUgNEbaYmAVL6bXl0nJRc+1S72ua/D/cTjGPlQj7eUqd7A096rYlRjdPYlhz7VIvxpVG3cemDKF+WAwLY/6XelOZKTXXzsC4xvDjjtSN6kHLhLke6PrwM8h1raf40qjrGO7H9aTEbduucjS04ZrYU/4iuS5Z2Hdt0rvCLFdmLEXcU30AGddST62o+sLcf5l6k7CP+ru4pLYqX/VFyxbm/utQbx/r22ZEbTb2f5I2kns1Y1OQR8ZyofX+TjJxj1Rz7QQVnf1QzR26Oth0ueJVYcRP6ZUPac/Rx/5M6ixO1dhSrT3Y1DpiYmx3tF4ZUdpz9LD/dSg9PXES0LB71BwcGjKROuV28lnvnv7HHJsezheBGH5+X2CfSfRbMKW+5aGs3JFjMrjGibJc0S7TJzqjHrh2hDybj9XRXNZa89Aro55XBdbW5wti2c/5WJ7jJ1RolVUn/HWpb0I58Tziup6Rx7Dm2hnbRP1GM9PW/NFmQ4PtVRVN63Wvxfmu5sowDMMwDMMwDMMwDMMwDMMwDMMwzL+CpT//F/6beoV8zb2Jmt4Qryx6lTUCsENQ75HOkhXAO3EPVgyQtKtUy3C/e+FJg17Zjnew1Xrdb9InbG4WqfUAftG+WhLwPVyfg536+MU7m4C1CMk4ZznpXZzDYI1PDL2nS1hpvc5cNd7E2sJg05Fe7/7d3Fln8Cvc3bwB616auxsKl4WPghjemHrDqyDWeu1UNW5s2btPnSQ75oOdunEwWazfwgVG0kqluYCM9OIjWOGnfA2b9G4Ha63XKpvQ8perTvTifJNhi6+WMWmi7smEZf6G8MmhlyGq+NqP8GV84TLuJr7UIQVx+bDEoEpRZIz42gs40OuN4Mv8hXzelV7KX1isH+ewTWckikyVv+CfHuqVF7I16gN0VKypX6wPsE+zFPzkinolU9UH8OMGvSpnZqKsv13p/RsMun6X5x/y2LeAr8O66lsBwzBMP/wJfyGq8pgBk6IAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(\"./media/placeholder.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "keywords"
    ]
   },
   "source": [
    "FirstKeyword, SecondKeyword, AlwaysSeparatedByAComma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "abstract"
    ]
   },
   "source": [
    "Many of the tools digital humanists use have come from a variety of disciplines outside of history. As a consequence, many digital-history methods sections focus on how a tool developed by non-historians might support, or need to be adapted for, particular historical questions. Few digital tools have been developed by and for historians with a specific eye to the methdological and theoretical explorations of design principles that anchor digital-history-specific tool development in historiographic practices.\n",
    "\n",
    "This article introduces Design Based History Research (DBHR) as a methodological bridge between the practices of digital-history tool design, the use of digital methods to create historical argumentation, and social-science-inspired methodological innovation. Design Based Research (DBR) is an approach to studying learning theory by integrating that theory into a design, implementing the design, and then studying the design as a way of modifying both the theory and the design that aims to reaify it. DBHR is an adaptation of the DBR approach grounded in the unique needs of history and historiography.\n",
    "\n",
    "We aim to illustrate DBHR by describing the design and use of Net.Create, a user-focused network-analysis tool that prioritizes historiographic practices (evidence interpretation, citation preservation, and historiographic debate) in its feature development and user-interface choices. In the narrative layer, we document how the needs of digital historians shaped the current design of Net.Create, and in the hermeneutic layer, we explore the connections between specific tool features and their operation, and how those tool features support the digital-history needs we identified.\n",
    "\n",
    "We will then extend the narrative, supported by the data layer, to present the human-computer-interaction analysis and user-entered network data that shaped each stage of our feature development around digital history practices: simultaneous data entry supports historiographic debate; revision of network taxonomy and network data in an easy-to-use interface to support interpretation and reinterpretation of evidence by many collaborators simultaneously; and data provenance features that expose the researchers' positionality and preserve the original citations for each network datapoint to support the integration of close-reading analytical practices. We will describe each development stage in the narrative layer and use the code/data layer to present user-behaviors, log files, and user-generated network data that allowed us to evaluate how effectively our digital-history tool-design choices supported the historiographic practices we identified as important to the practice of collaborative digital history.\n",
    "\n",
    "In the process of this study, we aim to shape the future of digital-history tool-building research through the articulation of concurrent and intertwined development of historical theory, digital-history tools, and collaborative historical methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction: Archival Boxes and Computational Black Boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All history starts in the archives: boxes, folders, . So, I’m not going to make you do anything digital, but I do want you to think back to the last time you were in an archive, and you had a box sitting in front of you waiting to be opened. It was probably a long trip. It probably took you a lot of time and effort in getting past the bureaucracy if necessary for a business trip as I’ve been talking to Colin about. And when you get to it, you’re sorting through everything, you’ve got indexing to do, note-taking, a list of documents that you expected. Maybe there might be something missing, you have to ask the archivist for, and you mark the stuff that works with your current research project. You put the stuff aside that’s cool, that you don’t know how it fits in yet, and you take notes on the weird stuff that you know is going to become an article. Opening the box is the easiest part of that. When we talk about computing, we are talking about computational black boxes, and exactly the opposite. Bruno Latour describes these roughly as systems that are so complex that we can’t actually wrap our heads around them. So we just put boxes around them. We give it stuff, we take the stuff back, and then we forget what’s in the middle. Every black box that you encounter is hidden behind a search box. So we come across them all the time, it’s not actually difficult to find them. You don’t have to pay money. You don’t have to work with travel. Yes, you get great results back for them, but how do those results get generated? What did you put in? How did the algorithm work with what you put in to give you back the results that you got? And when we do this, probably, especially when we’re in the middle of a historiographic project, hundreds of times a day. Even if we do understand how the algorithms in the box work, though, the tool is still going to constrain our results. The priorities of the people who built the box shape our priorities. So, that’s where I want to start. If it wasn’t filled with someone with a historian’s skill set, can it serve our needs? <cite data-cite=\"undefined\"></cite>\n",
    "\n",
    "# Black Box of Digital History\n",
    "\n",
    "Sometimes, yes, but in my case, I encountered this gap for the first time, and I’ve got Latin here because I’m going to talk about how I got here. I encountered this gap between what digital historians and digital humanities do, what tools are available to us, and my sources for the first time in 2011 when I was thinking about laying patterns around the roots of early medieval Episcopal power and authority. I had a large corpus of Latin Saints lives and Bishops lives. I knew what I was looking for was probably too big for me to comprehend, but also that there were probably patterns that I couldn’t see because I have a modern perspective on the Latin that doesn’t match the perspective that an eighth or ninth century Bishop would. So I wanted to look at topic modeling, which looks at those large scale latent patterns by telling you when words co-occur in larger bodies of text. And I wanted to look at corpus linguistics which lets you search for specific words in the text that you’ve identified as interesting based on the topic model, and see what’s around them in the sentence level. So big flyover sentence level. But the only tools that there were out there were built for collections of text in modern languages that are divided evenly into like 500 word chunks. And then those are divided evenly into 500 word chunks that arent actually meaningful for the person who wrote them that way. It expected specific word ordering for English is dependent, Latin is not. I had to think about 100 percent normalized stuff. So there’s lots of problems, right? Historical sources aren’t uniform in length or language. In some cases the variance of the Latin that I was working with words weren’t different, but they might as well have been different languages. Worse though, talking about linear corpus linguistics took out all of my citations. I couldn’t get the results back and then go find the spot in the text that the computational tools were highlighting for me. And that’s a real problem for historians. So I figured out an automated programing approach to get around those problems. You can see some of that here. I’ve pulled all of the words into separate entries in a database. I figured out what, by working backwards from the word in the text, what the root word was. I gave myself a word order, you can’t see that here, but I’ve got a word book and a word chapter, so that I can actually find the original word that generated the topic modeling results. And I wrote a results only article from the initial searches that tie the latent language in my medeval saints’ lives to the language in the Vulgate’s Bible’s version of the Book of Kings. Then I went shopping around the method’s piece because surely other people had experienced this. I’ll come back to this at the end, but the short version was, from several journals: “BLAGH. Who uses Latin?” That’s not enough, but yes, fair. But the way that I pitched it was that maybe we can use this with other languages. And the response was that there weren’t enough other people doing this in other languages that weren’t already suited for the topic models, so it didn’t make sense. But over the last seven years, I’ve gone back to that specific set of barriers:\n",
    "- Applicability\n",
    "- what historians need\n",
    "- how we track citations and historiography.\n",
    "\n",
    "As I thought about the similar barriers or the magnitude of projects that I’m going to talk about over the course of this talk, and the big question each time that governs those smaller questions was how would I design something, a tool or a method, with a historian in mind? Not just the me of seven years ago, but anybody. A historian who needs to build arguments with messy, varied sources, text and material like in lots of languages and forums, and be able to integrate the computational results with close reading because the citations are intact. So, on that note, we’re going to step way outside the bounds of typical history talk.\n",
    "\n",
    "# Anchoring Digital History Methods…\n",
    "\n",
    "We’re going to talk about nerdy social science. There are two questions that are implicit in the subtitle of today’s talk. So, anchoring digital history methods and tool development in historiography through design-based history research. I don’t usually start by saying, oh, I want clean data for something, right? I start by saying, I have this question about latent patterns of Medeval Saints’ Lives. And probably you also start there. That becomes two separate questions: What tools are out there to answer my questions and how do we use them to answer my questions? So tool design and method design. Sort of separate, but interconnected, and in a feedback. Lots of historians use digital tools in a method piece in digital humanities journals which means that we don’t encounter that much before reading. The historians who publish in traditional “history” often elite their methods because the editors have asked them to, to make it more of a narrative. What that means is that we don’t get examples for how they use the tools which tools work best, and what methods we can put around them to treat our sources. When I started my current employment in 2015, then, one of the things was to do exactly that to try and figure out if we could answer these questions in ways that could align with the research questions that we had, that other people on campus had, that our undergraduates had. So I started looking elsewhere for good solutions and not just made-up solutions. I’m a historian, I wanted to find them in the literature. That literature came from social scientists.\n",
    "\n",
    "# Design Based Research\n",
    "\n",
    "I found out in 2018, when I started working on NetCreate, that there is a sort of a solution for specialists to who need to develop and explain computational and methodological black-box and social science. You can work collaboratively with other researchers to open up new questions that traditional social sciences researchers can then take up. The solution is design based research. The missing word in there that’s in my talk title, but I want to move through DBR in its social science forms, so that we can look at the comparisons. DBR is designed for, and by, and here I’m quoting Shattuck, “for and by educators who seek to increase the impact transfer and translation of educational research into improved practice”. It stresses the need for theory building, the development and design principles that guide, inform, and improve both practice and research in educational contexts. In other words, if you strip that down into understandable language that makes sense for historians, DBR tracks change and continuity over time in the design of a research tool, and the methods surrounding it. Each sector has a theory to look at how people responded to the tool and the design, why their behaviors changed or didn’t, and it’s literally a history project. The first time I encountered DBR that link wasn’t immediately obvious because the vocabulary is really social science-y, right? And besides, this mixed method is collaborative. And that makes sense, but how do we apply that to us? So that’s why I started thinking about is:  how I could make that aha moment that I had more visible for historians.\n",
    "\n",
    "# Design Based HISTORY Research:\n",
    "\n",
    "So, let’s talk about design based history research. So let’s take some of the language, and the methods because the methods are very specific to social science and qualitative and quantitative research that has replicability requirements, which we don’t have, and make it work for historians. So, if there’s theory driven development of educational design and methods, what we want is the development of tools and methods designed to answer questions about change and continuity. We want to refine and iterate those tools and methods based on historical arguments at small scale, so that we’re not wasting our time on really big stuff and finding out that it doesn’t work. We want to do that collaboratively. And we want to make sure that the impact makes it to both sets of the digital humanities and digital history audience, the folks in the sub-fields with more traditional history projects and the folks working out the methods, and specifics.  So other thing that I did was take the larger bullet points that Anderson and Shattuck talk about and rewrite them for historians as I was thinking about what design-based history research looks like. The specifics helped me think a little more deeply about what each of those stages look like and I want to highlight a few of those because there’s an emphasis on design first, collaboration second, and partnerships. So that means that I can do some individual research on my own and then use the tools and methods that come out of that research and collaboration with other folks in the department; we’ve got a couple of examples of that. We can also think about a design-based history research position as a sort of stats person in social science. There’s a nice parallel. Statisticians in social science work out the stats and then they collaborate with someone who has a need that isn’t met by current stats or purchase. Both people get a research article out of it, the method makes its way into the discipline, so that other people using that new statistical tool can hand wave at it, talk about their method and make their method transparent, and not spend all the time on it in the article. And that’s what lets folks who are methodology and design focused produce new knowledge. So, as we go through these, I’m going to highlight these particular points: small-scale testing, tools designed for and by other historians, and linking those tools to continuity and change.\n",
    "\n",
    "# Case Studies\n",
    "\n",
    "The first place is to start with some case studies. I’ve also, because the case studies are sort of aligned with a past project-ish. The project I’m working on now, again-ish, and the project that will come in the future, and all of them are sort of interlaced with each other because some of them, I still have threads that are going, some of them are based in work that’s been done. We’re going to talk about NetCreate which is sort of my book-length digital history method and tool. We’re going to talk about mixed methods for collaboration in history, so that we can talk about how to be good collaborators, and explore a method that we can write up that lets us articulate our role in a research project when we collaborate. Because that’s not something that  historians have done very much yet, and then we’re going to talk about public digital history.\n",
    "\n",
    "# Net.Create\n",
    "\n",
    "Net.Create is again, a tool that fixes a gap that I found very early in my point here. And to articulate it effectively, I got to talk about what networks are. So, subject, verb, object. The circles in here are the subject and object in the sentence. They’re historical agents, the lines between them are the verbs, the connectors. The network is essentially a whole bunch of individual interactions between historical agents - people, places, things - articulated one-by-one, and then aggregated so that you can see the big patterns. There are some great things that it shows you, so it turns people that have lots and lots of connections into bigger planets. This is Claudius, in the late imperial world, this is Agrippina, this is Messalina. They have lots of interactions, so they’re big. They also have planetary gravity in this version of the layout, so dragging them around will drag people who are closely connected with them, to them in the visualization. What that lets us see are outliers, people who are influencers or power brokers, and points of connections between factions in a network. You can do that in a ‘change over time' way by adding things to these interactions. <cite data-cite=\"undefined\"></cite>\n",
    "\n",
    "# Net.Create(cont.)\n",
    "\n",
    "There are lots of barriers to using the organelles of history because of the way that network analysts think about networks. The data that network analysts use in networks is downloaded. So, you might have, depending on how the data is defined, if you post a reply to a friend’s post on Facebook, an interaction. But if you’re only friends, and you never reply to their posts, you won’t have a node-edge pair in the network. The data is given, literally aligned. It’s unconcerning, not in need of any additional interpretation. Historians don’t look at it that way. We revise our data, we revise what’s there, we ask different questions of it. And the example is in a network, you all might be a group. I have one connection to you as a group, but is that the right way to define the interaction that we are having right now? Do we want to have one connection between me and each one of you individually? Is it a one-way connection or is it a two-way connection? What happens when one of you asks questions at the end? Is that a second connection? Network analysts don’t allow for that kind of flexibility. The data is the way that it is when you download it and you work with it that way. So historians need tools that let us adjust to the network. Historians also need citations. Networks don’t just strip citations the way that computational analysis does. The most famous example of a network used in teaching takes the names out and replaces them with numbers. That’s terrible. Because we care not just about the trends and the patterns, but how people responded to the trends and patterns. We need to see people in context. That’s what got Net.Create started.\n",
    "\n",
    "# Net.Create(cont)\n",
    "\n",
    "So, we’re going through four rounds of design based revisions to this tool, talk about what drives each one of them. The first one is simultaneous data entry. There’s a lot of data in the network. It’s hard for one person to enter. So we started with ground principal and said, network data needs to be hand entered by historians, but there are lots of us. How do we make it possible for lots of us to do that? With the idea that we could root it in some educational research, collect computer-supported learning says if you have people interacting with data using a computational tool, the computational tool can push them to do particular kinds of things. One of the ways we used that was to have people in small groups putting in bits of data from one excerpt, while people from another group were putting in data from a second excerpt. But because it’s live and simultaneous, both in the data and visualization, they can see each other’s stuff popping up. And that prompts historiographic conversation. I just saw this pop-up here for the label that’s a few paragraphs down. Somebody else did that. How do we respond to that? Full-level historiography, right there, through simultaneous data collaboration. We also need citations and notes fields. And again, what we’re working with is the idea that, if you design the tool right, you can prompt people to do things, not just support it, encourage it. So, Net.Create has a required citation field and a required significance field so that every time someone interacts with information from a primary source, they’re prompted to record it, and we can find it again. So we can argue about what they entered. The idea here, the argument about what they entered is based in one of the single most important pieces of my literature reading, which is Hundrackers’ thesis, which says data isn’t data for humanists. It’s kept up. We take it, we interpret it, we change it, we revise it along the way. Because it’s argumentative in data form, it’s not just that when we write about it, we’re arguing with it. It’s the things that we do to our data are driven by our argument, so it’s not data anymore. And this gives us the ability to make that process visible. We also need to be able to divide the network so that we can answer those questions. Filter it, look for patterns in it. So there are filters that let us say: if in my nodes I mention ‘X’ feature, show me those nodes, and show me those nodes only. So that becomes a way of tracking the aggregate interactions, but we can also use it to find specific people, places, things, events, and citations. And that filtering is really important because it lets us ask the right question about our data. Activity theory is the brand new feature here. How do people use tools? How do the mediating features in the tools shape their behavior? Which is a fancy way of saying how do we get people to do history stuff with a computer software package? The thing that is present-ish is authorial perspective, right?\n",
    "\n",
    "# Net.Create(Up Next)\n",
    "\n",
    "So it’s not just about the author, it’s about who’s doing the data entry. We all bring a personal perspective to our history with us, so prominence matters in data. The feature that we’re building in right now for use in a sixth-grade math classroom, is ‘Who entered this?’, which is valuable for us. We’ll get funding for the sixth-grade math classroom, but historians can also use that so that as we have those questions about who entered what and why, we know exactly who entered it, and ask them. So this supports colloboration with other authors and other experts about this text.\n",
    "\n",
    "# Net.Create(Revisions)\n",
    "\n",
    "So what do digital industry outputs look like? So, I’ve taken all of the things that we just did and put them on one slide you can see the revision processes, the peer-reviewed grant submissions, right? Some of this is really familiar. We send it out. We get comments back, we change stuff. We send it out again, we get comments back, we change stuff, and maybe the third times a charm of the revise and resubmit works? But instead of articles, even though there are several articles here, or monographs, we’re looking at a combination of user feedback, peer-reviewed grants, use by other historians, and the real reward here is, in the last year and a half, since Net.Create and its documentation went live and was available to use without my help or without help from the team, fifteen or so folks have started to use it for their own research projects, including two folks who have finished their PhD based on a network analysis project using Net.Create here at IU and went on to faculty jobs elsewhere. So we’re having an impact.\n",
    "\n",
    "# Net.Create(distribution of women’s influence)\n",
    "\n",
    "And then there’s my book with Net.Create which took a really long time to create the tools, so I’m really just getting into some of this. And this is an article with Colin and an undergraduate who started using Net.Create very, very early on in her undergraduate career, is exceptionally smart, but also exceptionally good at bringing the two worlds together of data entry or papta-entry and historical thinking. So we built a collaborative structure around which she helped read Tastis and enter that data into a network. Colin’s bringing his historian graphic skill about great Roman imperial worlds to the project, and I’m bringing my network analysis to the project. And the end result in rough sketch argumentative form, which we’re writing up this semester is that women in the Roman imperial network are what we call eigenvector central which is a fancy way of saying people who don’t interact very much in the text as the original author recorded it, but who can pull on ties to many very important people, and operate their power behind the scenes. Access to gender, how Roman imperial dynasties get held together through networking analysis and with an undergraduate collaborator. So we’re training more people to do this with us. And that’s one of the key pieces of the collaborative piece that I want to talk about next…\n",
    "\n",
    "# MMatch\n",
    "\n",
    "Which takes out of late Imperial Rome and into Cuba in the 19th century, but keeps it in the world of collaborative history. The conversation process that Colin, Millie Aseafar, who is the undergraduate that we worked with, and I had is a mirror of some of the conversations that rooted a collaborative project with Arlene Diaz. For the second case study, Arlene and I are asking two questions. One: how does the latent imperialism of US Expansion Policy in the 19th century make its way into the language of US War Correspondence in Cuban produced primary sources? And two, how do we know that? How does the digital method help us with close reading? And how does it show us where our gaps are in that perspective in what people in the 19th century might have read and what we’re reading. I’ll come back and explain this graph at the end, and talk about what we’re doing. But what I’m going to ask questions about in the particular case study is epistemology. How do we know what we know? Historians root that in the space between our positionality, primary source, close reading, digital tools in this case, and the expertise contained in the historiographic body of secondary sources in which we situate ourselves as scholars of a particular subfield. Two things in digital history mess that up a bit. One is that the tools that we’re borrowing from other disciplines often assume the replicability of a project. That is, we give other people our data, we describe our methods, and they get exactly the same results that we do. It doesn’t work when you bring positionality into it. It’s especially hard when there’s more than one position in a collaborative or co-authored piece. How do we work with that? In some of the educational research that Net.Create is grounded in, there’s a method section in which we formally document the live in-person conversations that we have, and negotiation that we think we need to work through in view of the audience, through the reading audience about the design of a theory and how the integrate into our iterative revisions. And that marks our revisions in spaces of formal authorship. How do we do that in history? So, mixed methods to collaborative history. I say Match, Arlene says MMatch. I don’t care. It’s new enough that you all can decide. It surfaces because of how we staged it, the unacknowledged conversations that often shape our scholarship in hallways outside of conference presentations, thinking about Deborah’s. I like to go to dinner with people because that’s where I get great ideas because that actually is a set of authorship. We don’t often acknowledge it, right? Those articles in The Atlantic about the acknowledgements page in the 1950’s: my wife typed this, and helped me edit it and I never acknowledged it, and we never learn her name. How do we get past that?\n",
    "\n",
    "# MMatch(cont.)\n",
    "\n",
    "I’d done a DBR social science, like really hardcore DBR social science, Net.Create presentation in December. That’s when I really started thinking about how we might articulate, using DBR, some of these method questions in a way that makes sense for historians and lets us become good co-authors. So, I started looking again as I did with DBR at some of the literature on mixed methods and social science. This is Creswell and Tasha Cory. They outlined lots and lots of different flowcharts for the ways that you can mix quantitative and qualitative methods, that you can co-author stuff. And this one was the closest. I’m going to talk through this and I’m going to talk about what Arlene did to fix this for historians. The assumption that this makes is that qualitative and quantitative data collection happen on different sets of data in parallel. And then then eventually the quantitative and qualitative scholars come out and talk to each other. And then they write a results section, and they send it back. Well, there’s lots of problems with that. So, this is the same for us except it’s the same thing. Arlene and I aren’t working on two different datasets. We’re working on the same set of three war correspondence primary sources. So the data collection process isn’t separate. It’s a sourcing process. This can happen separately for historians and social sciences alike because what that lets us do is avoid cherry picking. So I’m not hearing from Arlene, like “Oh my God, I found this thing in the primary source”, and I’m like ooh, I should look at that in the digital source. We can do some of this separately. And it makes sense from a social science and history perspective for us to establish our own perspectives, our own positionality on the sources we’re working with. But then we can come back together and compare and relate. The thing is though again, as with that analogy of the Facebook network that we download, things change in history. We don’t just say, oh well that’s enough primary sources, we go back and fill the gaps in. So there needs to be a feedback loop somewhere in here, and it needs to be articulated well for us in a way that lets us go back here and still do this. Interpretation, great. But what you can’t see here, this is for notes in an article that I’m working up right now with Arlene. Steps 3 and 4 allow a more fluid cyclical revision of data and analysis that brings the last step into alignment with humanities interpretive approaches. So what does that look like?\n",
    "\n",
    "# MMatch(transparent practices)\n",
    "\n",
    "Again, what we did, and this is in an article which is going to the HR. It should have gone to the HR last week, but I was working on this. So it’s going to the HR this week. What we did was outline a series of steps and diagram it so that other people can follow what we’re doing, but also take into account some of the value that separate qualitative and quantitative analysis division that social sciences gives us. So, we want to source, we’re going to do parallel interpretation using a new method and an old method, or my method or Arlene’s method if those are both traditional methods, this isn’t digital history specific which is the beauty of it. Then we start talking to each other, dialogue based triangulation. This is the seminar, or the hallway conversation, but we record it so that we can talk about what we did, articulate it in the methods section, see where our arguments come from, and reshape them in a revised parallel or joint articulation of the argument and sourcing that we need to redo. We can do these things as many times as we want because these two steps help anchor us and help us document what we did. And then, we write them. The writing is a varied option. It gives us traces, we could go to the Journal of Digital History that has clickable buttons that lets us switch between the story or the narrative, the hermeneutic or the interpretation of the data, and the code. Depending on how deep the methods need to go, we could go somewhere like the Age or History Lab, which has some of that but not quite as complicated. We could go to a print journal. But the process allows us to choose what kind of medium we want, so that we can articulate our methods effectively in the right medium, in the right place, and to the right audience.\n",
    "\n",
    "# MMatch(men, women, machetes)\n",
    "\n",
    "So then we go back to this weird visual and now I’m going to talk a little bit about some of the history. We started with three War Correspondents: Sylvester Scoville, George Watson Rangal, and Berger Flint. All of whom spent time with Cuban insurgent generals in 1896 in the field. We worked through their work, documented what we did at each step, and we started with sourcing. So let’s go through that source extent. All three wrote about their experiences for a U.S audience. Flint produced books designed for general audiences, and Scoville produced mostly newspaper articles about this period of his exploits in Cuba. Our question, we wanted to know what the three correspondents were communicated to the U.S on two levels: what was overtly communicated that aligned with the U.S correspondents’ need to justify the war or to make it more popular stateside, and what latent patterns were missing either because the purpose was too big or because we’re imbedded in a slightly different imperialist moment and don’t have the necessary perspective to see some of the implicit messages that way. It made the method easy to choose, that’s topic modeling, I talked about the latency that topic modeling shows us. Topic modeling returns clusters of words that are distributed similarly across a different set of documents. We had to be careful because we had adapted the standards of chunking or dividing text equally into parts, we chose a set to divide by topics that have meaning for historians, so chapters, newspaper articles. But what that does is it screws up the distribution a little, so what we also did was draw on some of the work that Drew Golding has done which says that the results of a computational tool are themselves semi-primary sources, like they can be interpreted by historians. If you are open about how you chose to use the results to lead you back into the primary sources, it’s a valid way of treating a computational tool. The topic that’s highlighted here, number seven, is about she and her. It ended up being the core of the main argument and the anchor for the match conversation, we had in steps 3 and 4. And it’s the only topic that is heavily dependent on pronouns about girls. Not surprising in a military guerrila warfare context, but what was surprising? The appearance of the word ‘machete’ about halfway down. I had questions. Arlene had some answers. But the reason that I had questions, machete shows up in another topic that I nicknamed very early on in my part of the research, little men with machetes, because those three words appear very close to each other. So what I wanted to know is what’s happening with women with machetes and little men with machetes. Where’s the overlap there, and are we missing latent general norms here? We looked, as a consequence of these two articles, at a number of other topics. One of which was a historiographic source which talks about Amazon women with machetes as a common topic of newspaper articles designed to get people re-interested in the Cuban war. But when we went back to the primary sources, it was ‘Mrs. Hernandez, wife of Dr. Hernandez, with a machete helping the army get through the field’. It’s a very different kind of approach. We also found a number of topics that suggested that the Cuban army, in its latent language, was badly organized, weak, not worthy of self-governance. When we went back to the primary sources to look at a number of other things, including women with machetes, what we found was a latent emasculation of the Cuban insurgents combined with their weak, disorganized state, they were too girly. And Arlene found the key piece of it which is one of the sources, Flint, describing General Gomez as Little Machete. Take that where you will, we took it there, but it was beautiful to see some of the latency in there helping us find what we needed in the primary sources to connect the emasculation of the Cuban insurgents to the language that was being presented to the U.S audiences. And what was even better, we also decided that we needed to go back and look at perspectives from the Spanish-speaking folks. We looked at General Gomez’s own diary, we looked at Barnabe Goza’s diary, who was General Gomez’s chief of staff, in Spanish language form to see if they were missing that too. Did we miss it because we weren’t paying attention? Did we miss it because we were missing the U.S imperial’s context? Was there a linguistic problem? Barnabe Goza describes Flint, who described General Gomez as ‘Little Machete’, as the most fair of all of the U.S journalists. We didn’t miss it. As part of the context, the primary sources of being presented to the U.S public and the Spanish language speakers at the time missed it and so did we because we’re lacking some of that context. Topic modeling helped us find it. The most rewarding part of that argument though is the documentation that went in it. Match let us acknowledge, write out that argument process, write out the things that we did to get to that little machete moment. Talking about how we used our digital tool to close reading and our conversation and all of them are equally important in the development of the argument, an outcome that we hope will help model for other historians grappling with questions that might be solved by digital tools, collaboration, or both.\n",
    "\n",
    "# Community Archives Template\n",
    "\n",
    "So, if Net.Create had tool building driven by practices of historiography and matches driven by the need to formalize contributions to historiography that are informal in the interstitial spaces between our collaborators, our tools. The project that is moving into the future is Community Archive Jekyl template, which is a terrible name, but it’s the easiest to search. Search engines being what they are. This works backward from historiographic need to make the historiographic need manifest in a tool. The Greenville long-time community on the border of Indiana and Ohio, is a partner in one of our former graduate student’s research. After some time working with them, Jasma Agakundosasuden, now at Miami University in Ohio, works together with them to solve the problems that they had articulated to her which was that they had been collecting a community archive of sorts on Facebook and realized that they didn’t own their stuff. Huge problem. That request came roughly parallel to a history project that I was working on in an undergraduate class which offered solutions to quite a few issues that the long-time community raised with Jasma. But then it also raised a whole host of questions that couldn’t be answered with a simple history harvest or some sort of easy to use platform. As Jasma’s dissertation progressed, she started to patterns specifically oriented around how the women who were descendants from Greenville pre Civil War Black families took on the task of giving themselves a place history that was based on photos, oral history, photo albums, even plates of photos, material culture, and even annual homecoming events that brought that diaspora back to Greenville. We realized that we needed something better. In part because the first history harvests that are out there, history harvest started in the University of Nebraska with a platform called Omeka built by George Mason University. Omeka requires serious technical overhead. You’ve got to have a server, it costs a lot of money if you do it outside of an academic institution, it’s between $35-50 a month, and that’s not sustainable for a community like Greenville where they’re diasporic or they don’t all live in Greenville anymore. It also means that if they partner with an academic institution, the community fears that they’ll lose ownership of their own history. And that’s particularly important given Jasma’s development of descendant archival practices, where descendant women take responsibility for holding not just the homecoming events but the history of the community together. Several lines of archival and library literature address some of these ownership concerns, but a research partner that I’m supporting at IDAH with an Indigenous Collective in Los Angeles called EXHAM, is helping take that one step further to community ownership that includes academic institutional partnerships. Only if the community wants it, and that builds on a series of literature called minimal computing that is a big deal in digital humanities because as the Digital Humanities community has expanded globally, some of these questions about access to technology have come to bear in ways that don’t always make themselves visible in the U.S. So, this exhibit template is my part of that effort. From a practical perspective, it’s minimal computing. It’s just a free account on GitHub, and you can actually edit the files on your phone. No computers, no databases, no cost. From a more theoretical perspective though, descendant archival practices reshaped the language of the exhibit and its technical affordances from the ground up. The standards in histories are that contributors bring objects, literally it’s a language that gets used that comes out of Dublin Core Metadata Archive practices that let historians and archivists can find information online, but contributors give stuff to other people. Communities that are the stewards of their own history don’t contribute anything. They keep it and they get to choose who sees it. The exhibit template then that I’m building support both in Greenville long-time community, and you can see this at longtime.historyharvest.github.ai. I’ll post a link later. It’s also going to help us with that partnership with EXHAM. It shapes, and I’ve given you an example of some of things that we’re doing over here to help guide communities who are new to this. It shapes links between the languages of archivists or historians who are working with digital exhibits and the language of the community members who want to use for themselves. It links their vocabulary, their ownership, and their preferences to the discoverability that historians and archivists need if we want to work with this. It allows them to hide or show parts of the exhibit at will. Also, important, a set of archival practices outline the stakes for communities to build its own history, and the community archive’s template makes it possible to carry that forward to communities with minimal resources with rich pasts.\n",
    "\n",
    "# History Research\n",
    "\n",
    "So we’re back to the Latin word thing that I talked about at the very beginning. The article that made its publication was all results, and the one that didn’t was not going to be told by anyone, right? One journal said that they liked it, but didn’t see broad applicability. And so, it was to my great horror and surprise and eventual pride that last year at the Naval Conference, I saw the Yale Digital Humanities panel and it was almost identical, and they have publication for it. Okay, we’re all done, right? You see your argument in an article that you open up in the latest journal or whatever, damnit, it sucks! What if we saw it as an opportunity? There’s a straight line from the methods transparency work I did in that Latin lemmentizing project to match to methods as research with Arlene. Net.Create started working with DBR as a methodological foundation for our work in 2017. I used this motivation to bridge the DBR to DBHR gap for journal adrift digital history, the one with the heurmendics narrative code layer that exists now. Rather than see the Yale’s DH team’s project as a scoop, instead what’s happening is there’s enough of a groundswell that we can support that sort of project. And it’s in that timing that I think the opportunity is really key. What I hope I’ve done is demonstrate the value of articulating new or existing transparent methods that go with the development of historian designed digital tools. We’re in need of a way to communicate our methods, to make new tools for ourselves, to bring the tool, the method, and collaborative structures that work into our conversations in a transparent way. And there are only a few departments in the country that are positioned to do this. Clemson has the first digital history PhD program in the country. It’s run by Doug Seafelt, who got his digital history start in a tenure line job in Nebraska where they have a huge digital history program, except they didn’t like methods. He went to Ball State, he’s now in Clemson, He’s done an exceptional job of starting up that program, but it’s just him. I can think of at least ten of you that I’ve worked with, three of you I’ve co-authored with, we are unusually positioned here because we have both a methods person and a broad variety of people now have enough experience with some of these methods to collaborate. The history adaptation of DBHR might be new, but adapting it with a concrete name and a publication has only been possible because of the work that we’ve done already in this department. The research that I’ve already put into the public eye, the design work that has been done both on my own and in collaboration with a number of you. And I fit in because I can help us as a department repurpose the links between digital history tool building and building digital methods. And we can use that link to drive collaborative history research projects that expand our work not just to us, but to our undergraduates and graduates. We’ve got examples of that too. An article with Jasma about Senate archival practices and the minimal computing basis for it came out in Digital Humanities Quarterly last week. We’ve got an undergraduate working for us, three undergraduates in the last graduating class alone, who worked with me as authors on some of the projects that I’ve been doing. So what happens if we as a department make this part of our work? Some of us should be absolutely embedded in the world of monographs, others of us have some middle ground where we’re comfortable, others of us are going all the way to the end of that tool building world. But if we’re collaboratively working through it and we can articulate that as a department and as individuals, we have an unusual opportunity here to really be at the cutting edge of digital history in this country. I thank you all for your time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "hermeneutics"
    ]
   },
   "source": [
    "This is a hermeneutic paragraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jdh": {
     "module": "object",
     "object": {
      "source": [
       "table 1: label table 1"
      ]
     }
    },
    "tags": [
     "table-1"
    ]
   },
   "source": [
    "Editor|1641|1798|1916\n",
    "---|---|---|---\n",
    "Senan|0.55|0.4|0.3\n",
    "Henry|0.71|0.5|0.63"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "hidden"
    ]
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check your Python version\n",
    "from platform import python_version\n",
    "python_version()\n",
    "\n",
    "#!python -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas package needs to be added to the requirements.txt 's file \n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>PredominantDegree</th>\n",
       "      <th>HighestDegree</th>\n",
       "      <th>FundingModel</th>\n",
       "      <th>Region</th>\n",
       "      <th>Geography</th>\n",
       "      <th>AdmissionRate</th>\n",
       "      <th>ACTMedian</th>\n",
       "      <th>SATAverage</th>\n",
       "      <th>AverageCost</th>\n",
       "      <th>Expenditure</th>\n",
       "      <th>AverageFacultySalary</th>\n",
       "      <th>MedianDebt</th>\n",
       "      <th>AverageAgeofEntry</th>\n",
       "      <th>MedianFamilyIncome</th>\n",
       "      <th>MedianEarnings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama A &amp; M University</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Public</td>\n",
       "      <td>Southeast</td>\n",
       "      <td>Mid-size City</td>\n",
       "      <td>0.8989</td>\n",
       "      <td>17</td>\n",
       "      <td>823</td>\n",
       "      <td>18888</td>\n",
       "      <td>7459</td>\n",
       "      <td>7079</td>\n",
       "      <td>19500.0</td>\n",
       "      <td>20.629999</td>\n",
       "      <td>29039.0</td>\n",
       "      <td>27000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>University of Alabama at Birmingham</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Public</td>\n",
       "      <td>Southeast</td>\n",
       "      <td>Mid-size City</td>\n",
       "      <td>0.8673</td>\n",
       "      <td>25</td>\n",
       "      <td>1146</td>\n",
       "      <td>19990</td>\n",
       "      <td>17208</td>\n",
       "      <td>10170</td>\n",
       "      <td>16250.0</td>\n",
       "      <td>22.670000</td>\n",
       "      <td>34909.0</td>\n",
       "      <td>37200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>University of Alabama in Huntsville</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Public</td>\n",
       "      <td>Southeast</td>\n",
       "      <td>Mid-size City</td>\n",
       "      <td>0.8062</td>\n",
       "      <td>26</td>\n",
       "      <td>1180</td>\n",
       "      <td>20306</td>\n",
       "      <td>9352</td>\n",
       "      <td>9341</td>\n",
       "      <td>16500.0</td>\n",
       "      <td>23.190001</td>\n",
       "      <td>39766.0</td>\n",
       "      <td>41500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alabama State University</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Public</td>\n",
       "      <td>Southeast</td>\n",
       "      <td>Mid-size City</td>\n",
       "      <td>0.5125</td>\n",
       "      <td>17</td>\n",
       "      <td>830</td>\n",
       "      <td>17400</td>\n",
       "      <td>7393</td>\n",
       "      <td>6557</td>\n",
       "      <td>15854.5</td>\n",
       "      <td>20.889999</td>\n",
       "      <td>24029.5</td>\n",
       "      <td>22400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The University of Alabama</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Public</td>\n",
       "      <td>Southeast</td>\n",
       "      <td>Small City</td>\n",
       "      <td>0.5655</td>\n",
       "      <td>26</td>\n",
       "      <td>1171</td>\n",
       "      <td>26717</td>\n",
       "      <td>9817</td>\n",
       "      <td>9605</td>\n",
       "      <td>17750.0</td>\n",
       "      <td>20.770000</td>\n",
       "      <td>58976.0</td>\n",
       "      <td>39200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1289</th>\n",
       "      <td>University of Connecticut-Avery Point</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Public</td>\n",
       "      <td>New England</td>\n",
       "      <td>Mid-size Suburb</td>\n",
       "      <td>0.5940</td>\n",
       "      <td>24</td>\n",
       "      <td>1020</td>\n",
       "      <td>12946</td>\n",
       "      <td>11730</td>\n",
       "      <td>14803</td>\n",
       "      <td>18983.0</td>\n",
       "      <td>20.120001</td>\n",
       "      <td>86510.0</td>\n",
       "      <td>49700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1290</th>\n",
       "      <td>University of Connecticut-Stamford</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Public</td>\n",
       "      <td>New England</td>\n",
       "      <td>Mid-size City</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>21</td>\n",
       "      <td>1017</td>\n",
       "      <td>13028</td>\n",
       "      <td>4958</td>\n",
       "      <td>14803</td>\n",
       "      <td>18983.0</td>\n",
       "      <td>20.120001</td>\n",
       "      <td>86510.0</td>\n",
       "      <td>49700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1291</th>\n",
       "      <td>California State University-Channel Islands</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Public</td>\n",
       "      <td>Far West</td>\n",
       "      <td>Mid-size Suburb</td>\n",
       "      <td>0.6443</td>\n",
       "      <td>20</td>\n",
       "      <td>954</td>\n",
       "      <td>22570</td>\n",
       "      <td>12026</td>\n",
       "      <td>8434</td>\n",
       "      <td>12500.0</td>\n",
       "      <td>24.850000</td>\n",
       "      <td>32103.0</td>\n",
       "      <td>35800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1292</th>\n",
       "      <td>DigiPen Institute of Technology</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Private For-Profit</td>\n",
       "      <td>Far West</td>\n",
       "      <td>Small City</td>\n",
       "      <td>0.6635</td>\n",
       "      <td>28</td>\n",
       "      <td>1225</td>\n",
       "      <td>37848</td>\n",
       "      <td>5998</td>\n",
       "      <td>7659</td>\n",
       "      <td>19000.0</td>\n",
       "      <td>21.209999</td>\n",
       "      <td>68233.0</td>\n",
       "      <td>72800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1293</th>\n",
       "      <td>Neumont University</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>Private For-Profit</td>\n",
       "      <td>Rocky Mountains</td>\n",
       "      <td>Mid-size City</td>\n",
       "      <td>0.7997</td>\n",
       "      <td>25</td>\n",
       "      <td>1104</td>\n",
       "      <td>37379</td>\n",
       "      <td>3298</td>\n",
       "      <td>6991</td>\n",
       "      <td>22313.0</td>\n",
       "      <td>24.750000</td>\n",
       "      <td>39241.0</td>\n",
       "      <td>37300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1294 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Name PredominantDegree  \\\n",
       "0                        Alabama A & M University        Bachelor's   \n",
       "1             University of Alabama at Birmingham        Bachelor's   \n",
       "2             University of Alabama in Huntsville        Bachelor's   \n",
       "3                        Alabama State University        Bachelor's   \n",
       "4                       The University of Alabama        Bachelor's   \n",
       "...                                           ...               ...   \n",
       "1289        University of Connecticut-Avery Point        Bachelor's   \n",
       "1290           University of Connecticut-Stamford        Bachelor's   \n",
       "1291  California State University-Channel Islands        Bachelor's   \n",
       "1292              DigiPen Institute of Technology        Bachelor's   \n",
       "1293                           Neumont University        Bachelor's   \n",
       "\n",
       "     HighestDegree        FundingModel           Region        Geography  \\\n",
       "0         Graduate              Public        Southeast    Mid-size City   \n",
       "1         Graduate              Public        Southeast    Mid-size City   \n",
       "2         Graduate              Public        Southeast    Mid-size City   \n",
       "3         Graduate              Public        Southeast    Mid-size City   \n",
       "4         Graduate              Public        Southeast       Small City   \n",
       "...            ...                 ...              ...              ...   \n",
       "1289      Graduate              Public      New England  Mid-size Suburb   \n",
       "1290      Graduate              Public      New England    Mid-size City   \n",
       "1291      Graduate              Public         Far West  Mid-size Suburb   \n",
       "1292      Graduate  Private For-Profit         Far West       Small City   \n",
       "1293    Bachelor's  Private For-Profit  Rocky Mountains    Mid-size City   \n",
       "\n",
       "      AdmissionRate  ACTMedian  SATAverage  AverageCost  Expenditure  \\\n",
       "0            0.8989         17         823        18888         7459   \n",
       "1            0.8673         25        1146        19990        17208   \n",
       "2            0.8062         26        1180        20306         9352   \n",
       "3            0.5125         17         830        17400         7393   \n",
       "4            0.5655         26        1171        26717         9817   \n",
       "...             ...        ...         ...          ...          ...   \n",
       "1289         0.5940         24        1020        12946        11730   \n",
       "1290         0.4107         21        1017        13028         4958   \n",
       "1291         0.6443         20         954        22570        12026   \n",
       "1292         0.6635         28        1225        37848         5998   \n",
       "1293         0.7997         25        1104        37379         3298   \n",
       "\n",
       "      AverageFacultySalary  MedianDebt  AverageAgeofEntry  MedianFamilyIncome  \\\n",
       "0                     7079     19500.0          20.629999             29039.0   \n",
       "1                    10170     16250.0          22.670000             34909.0   \n",
       "2                     9341     16500.0          23.190001             39766.0   \n",
       "3                     6557     15854.5          20.889999             24029.5   \n",
       "4                     9605     17750.0          20.770000             58976.0   \n",
       "...                    ...         ...                ...                 ...   \n",
       "1289                 14803     18983.0          20.120001             86510.0   \n",
       "1290                 14803     18983.0          20.120001             86510.0   \n",
       "1291                  8434     12500.0          24.850000             32103.0   \n",
       "1292                  7659     19000.0          21.209999             68233.0   \n",
       "1293                  6991     22313.0          24.750000             39241.0   \n",
       "\n",
       "      MedianEarnings  \n",
       "0              27000  \n",
       "1              37200  \n",
       "2              41500  \n",
       "3              22400  \n",
       "4              39200  \n",
       "...              ...  \n",
       "1289           49700  \n",
       "1290           49700  \n",
       "1291           35800  \n",
       "1292           72800  \n",
       "1293           37300  \n",
       "\n",
       "[1294 rows x 16 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"https://raw.githubusercontent.com/lux-org/lux-datasets/master/data/college.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "citation-manager": {
   "items": {}
  },
  "cite2c": {
   "citations": {
    "32868/FZ539MBE": {
     "URL": "https://voyant-tools.org/",
     "accessed": {
      "day": 25,
      "month": 1,
      "year": 2019
     },
     "author": [
      {
       "family": "Sinclair",
       "given": "Stéfan"
      },
      {
       "family": "Rockwell",
       "given": "Geoffrey"
      }
     ],
     "container-title": "Voyant Tools",
     "id": "32868/FZ539MBE",
     "issued": {
      "year": 2020
     },
     "title": "Voyant Tools",
     "type": "webpage"
    },
    "undefined": {
     "URL": "https://www.netcreate.org/",
     "accessed": {
      "day": 8,
      "month": 5,
      "year": 2021
     },
     "author": [
      {
       "family": "Craig",
       "given": "Kalani"
      },
      {
       "family": "Danish",
       "given": "Joshua"
      }
     ],
     "id": "undefined",
     "issued": {
      "year": 2018
     },
     "title": "Net.Create",
     "type": "book"
    }
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
